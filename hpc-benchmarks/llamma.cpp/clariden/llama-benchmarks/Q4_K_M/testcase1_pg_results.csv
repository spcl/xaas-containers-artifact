build_commit,build_number,cpu_info,gpu_info,backends,model_filename,model_type,model_size,model_n_params,n_batch,n_ubatch,n_threads,cpu_mask,cpu_strict,poll,type_k,type_v,n_gpu_layers,split_mode,main_gpu,no_kv_offload,flash_attn,tensor_split,use_mmap,embeddings,n_prompt,n_gen,test_time,avg_ns,stddev_ns,avg_ts,stddev_ts
"bc091a4d","5124","OpenBLAS, CPU","NVIDIA GH200 120GB","CUDA,BLAS","/iopsstor/scratch/cscs/ealnuaim/llama-builds/testcase0/llama.cpp/models/13B/llama-2-13b-chat.Q4_K_M.gguf","llama 13B Q4_K - Medium","7865210880","13015864320","2048","512","16","0x0","0","50","f16","f16","99","layer","0","0","0","0.00","1","0","512","0","2025-04-13T16:02:55Z","97763300","229454","5237.167121","12.261040"
"bc091a4d","5124","OpenBLAS, CPU","NVIDIA GH200 120GB","CUDA,BLAS","/iopsstor/scratch/cscs/ealnuaim/llama-builds/testcase0/llama.cpp/models/13B/llama-2-13b-chat.Q4_K_M.gguf","llama 13B Q4_K - Medium","7865210880","13015864320","2048","512","16","0x0","0","50","f16","f16","99","layer","0","0","0","0.00","1","0","0","128","2025-04-13T16:02:59Z","832971928","450428","153.666687","0.083218"
"bc091a4d","5124","OpenBLAS, CPU","NVIDIA GH200 120GB","CUDA,BLAS","/iopsstor/scratch/cscs/ealnuaim/llama-builds/testcase0/llama.cpp/models/13B/llama-2-13b-chat.Q4_K_M.gguf","llama 13B Q4_K - Medium","7865210880","13015864320","2048","512","16","0x0","0","50","f16","f16","99","layer","0","0","0","0.00","1","0","512","128","2025-04-13T16:03:32Z","1018178405","316105","628.573594","0.194476"
