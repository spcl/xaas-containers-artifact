build_commit,build_number,cpu_info,gpu_info,backends,model_filename,model_type,model_size,model_n_params,n_batch,n_ubatch,n_threads,cpu_mask,cpu_strict,poll,type_k,type_v,n_gpu_layers,split_mode,main_gpu,no_kv_offload,flash_attn,tensor_split,use_mmap,embeddings,n_prompt,n_gen,test_time,avg_ns,stddev_ns,avg_ts,stddev_ts
"bc091a4d","5124","CPU","","CPU","/iopsstor/scratch/cscs/ealnuaim/llama-builds/testcase0/llama.cpp/models/13B/llama-2-13b-chat.Q4_0.gguf","llama 13B Q4_0","7365089280","13015864320","2048","512","16","0x0","0","50","f16","f16","99","layer","0","0","0","0.00","1","0","512","0","2025-04-13T16:48:33Z","4504838403","50130316","113.670080","1.337214"
"bc091a4d","5124","CPU","","CPU","/iopsstor/scratch/cscs/ealnuaim/llama-builds/testcase0/llama.cpp/models/13B/llama-2-13b-chat.Q4_0.gguf","llama 13B Q4_0","7365089280","13015864320","2048","512","16","0x0","0","50","f16","f16","99","layer","0","0","0","0.00","1","0","0","128","2025-04-13T16:51:38Z","8241121999","11888899","15.531897","0.022333"
"bc091a4d","5124","CPU","","CPU","/iopsstor/scratch/cscs/ealnuaim/llama-builds/testcase0/llama.cpp/models/13B/llama-2-13b-chat.Q4_0.gguf","llama 13B Q4_0","7365089280","13015864320","2048","512","16","0x0","0","50","f16","f16","99","layer","0","0","0","0.00","1","0","512","128","2025-04-13T16:57:08Z","13118119932","9370452","48.787503","0.034741"
