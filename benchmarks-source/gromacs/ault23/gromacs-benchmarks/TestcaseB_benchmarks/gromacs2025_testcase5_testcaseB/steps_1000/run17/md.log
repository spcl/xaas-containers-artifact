                   :-) GROMACS - gmx mdrun, 2025.0-spack (-:

Copyright 1991-2025 The GROMACS Authors.
GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

                         Current GROMACS contributors:
       Mark Abraham           Andrey Alekseenko           Brian Andrews       
      Vladimir Basov              Paul Bauer                Hugh Bird         
      Eliane Briand               Ania Brown              Mahesh Doijade      
      Giacomo Fiorin          Stefan Fleischmann          Sergey Gorelov      
   Gilles Gouaillardet            Alan Gray              M. Eric Irrgang      
   Farzaneh Jalalypour         Petter Johansson          Carsten Kutzner      
    Grzegorz Łazarski         Justin A. Lemkul          Magnus Lundborg      
       Pascal Merz             Vedran Miletić            Dmitry Morozov      
     Lukas Müllender            Julien Nabet             Szilárd Páll      
 Andrea Pasquadibisceglie     Michele Pellegrino         Nicola Piasentin     
     Daniele Rapetti         Muhammad Umair Sadiq         Hubert Santuz       
      Roland Schulz             Michael Shirts           Tatiana Shugaeva     
     Alexey Shvetsov            Philip Turner            Alessandra Villa     
 Sebastian Wingbermühle  

                         Previous GROMACS contributors:
        Emile Apol             Rossen Apostolov           James Barnett       
  Herman J.C. Berendsen         Cathrine Bergh             Par Bjelkmar       
      Christian Blau          Viacheslav Bolnykh            Kevin Boyd        
    Aldert van Buuren          Carlo Camilloni           Rudi van Drunen      
      Anton Feenstra           Oliver Fleetwood            Vytas Gapsys       
       Gaurav Garg             Gerrit Groenhof            Bert de Groot       
      Anca Hamuraru           Vincent Hindriksen          Victor Holanda      
     Aleksei Iupinov              Joe Jordan            Christoph Junghans    
    Prashanth Kanduri        Dimitrios Karkoulis           Peter Kasson       
      Sebastian Kehl           Sebastian Keller             Jiri Kraus        
       Per Larsson              Viveca Lindahl            Erik Marklund       
    Pieter Meulenhoff           Teemu Murtola              Sander Pronk       
      Alfons Sijbers            Balint Soproni         David van der Spoel    
      Peter Tieleman            Carsten Uphoff             Jon Vincent        
     Teemu Virolainen         Christian Wennberg           Maarten Wolf       
      Artem Zhmurov       

                  Coordinated by the GROMACS project leaders:
                           Berk Hess and Erik Lindahl

GROMACS:      gmx mdrun, version 2025.0-spack
Executable:   /scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/gromacs-2025.0-ucuxcyvfffej6s2jytwrgveyytdfzdqw/bin/gmx_mpi
Data prefix:  /scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/gromacs-2025.0-ucuxcyvfffej6s2jytwrgveyytdfzdqw
Working dir:  /scratch/mcopik/xaas-containers-artifact/benchmarks-source/gromacs/ault23/gromacs-benchmarks/TestcaseB_benchmarks/gromacs2025_testcase5_testcaseB/steps_1000/run17
Process ID:   2483517
Command line:
  gmx_mpi mdrun -s /scratch/mcopik/xaas-containers-artifact/data/gromacs/GROMACS_TestCaseB/lignocellulose.tpr -ntomp 64 -gpu_id 0 -nsteps 1000

GROMACS version:     2025.0-spack
Precision:           mixed
Memory model:        64 bit
MPI library:         MPI
MPI library version: MPICH Version:      4.3.1 MPICH Release date: Fri Jun 20 09:24:41 AM CDT 2025 MPICH ABI:          17:1:5 MPICH Device:       ch4:ofi MPICH configure:    --prefix=/scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/mpich-4.3.1-iwbuglxzla7gisnlgdllob6hdzjjzbzn --disable-maintainer-mode --disable-silent-rules --enable-shared --with-pm=hydra --enable-romio --without-ibverbs --enable-wrapper-rpath=yes --with-yaksa=/scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/yaksa-0.3-6c3f5zh7zs7xuctnb5acjc3ubgfc3luv --without-ze --with-hwloc=/scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/hwloc-2.11.1-4adtlqiznt6pgfqmxsar7aef3gx5rcyu --enable-fortran --with-slurm=no --without-cuda --without-hip --with-device=ch4:ofi --with-libfabric=/scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/libfabric-2.2.0-6aepmhvd2ausqv737r4g5q723p7lxmxs --enable-libxml2 --with-datatype-engine=auto MPICH CC:           /scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/compiler-wrapper-1.0-pwvcynlepsfvtofklxk2y55vmwbo7aoj/libexec/spack/gcc/gcc     -O2 MPICH CXX:          /scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/compiler-wrapper-1.0-pwvcynlepsfvtofklxk2y55vmwbo7aoj/libexec/spack/gcc/g++   -O2 MPICH F77:          /scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/compiler-wrapper-1.0-pwvcynlepsfvtofklxk2y55vmwbo7aoj/libexec/spack/gcc/gfortran   -O2 MPICH FC:           /scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/compiler-wrapper-1.0-pwvcynlepsfvtofklxk2y55vmwbo7aoj/libexec/spack/gcc/gfortran   -O2 MPICH features:     threadcomm 
OpenMP support:      enabled (GMX_OPENMP_MAX_THREADS = 128)
GPU support:         CUDA
NBNxM GPU setup:     super-cluster 2x2x2 / cluster 8 (cluster-pair splitting on)
SIMD instructions:   AVX_512
CPU FFT library:     fftw-3.3.10-sse2-avx-avx2-avx2_128-avx512
GPU FFT library:     cuFFT
Multi-GPU FFT:       HeFFTe 2.4.1 with cuFFT backend
RDTSCP usage:        enabled
TNG support:         enabled
Hwloc support:       hwloc-2.11.1
Tracing support:     disabled
C compiler:          /scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/compiler-wrapper-1.0-pwvcynlepsfvtofklxk2y55vmwbo7aoj/libexec/spack/gcc/gcc GNU 11.5.0
C compiler flags:    -fexcess-precision=fast -funroll-all-loops -march=skylake-avx512 -Wno-missing-field-initializers -O3 -DNDEBUG
C++ compiler:        /scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/compiler-wrapper-1.0-pwvcynlepsfvtofklxk2y55vmwbo7aoj/libexec/spack/gcc/g++ GNU 11.5.0
C++ compiler flags:  -fexcess-precision=fast -funroll-all-loops -march=skylake-avx512 -Wno-missing-field-initializers -Wno-old-style-cast -Wno-cast-qual -Wno-suggest-override -Wno-suggest-destructor-override -Wno-zero-as-null-pointer-constant -Wno-cast-function-type-strict SHELL:-fopenmp -O3 -DNDEBUG
BLAS library:        External - user-supplied
LAPACK library:      External - user-supplied
CUDA compiler:       /scratch/mcopik/xaas-containers-artifact/dependencies/spack_2025/opt/spack/linux-skylake_avx512/cuda-12.9.0-5d5ko7iqhvjmccpitfbpbxv6aupjcu4l/bin/nvcc nvcc: NVIDIA (R) Cuda compiler driver;Copyright (c) 2005-2025 NVIDIA Corporation;Built on Wed_Apr__9_19:24:57_PDT_2025;Cuda compilation tools, release 12.9, V12.9.41;Build cuda_12.9.r12.9/compiler.35813241_0
CUDA compiler flags: -O3 -DNDEBUG
CUDA driver:         12.80
CUDA runtime:        12.90


Running on 1 node with total 32 cores, 64 processing units, 4 compatible GPUs
Hardware detected on host ault23.cscs.ch (the node of MPI rank 0):
  CPU info:
    Vendor: Intel
    Brand:  Intel(R) Xeon(R) Gold 6130 CPU @ 2.10GHz
    Family: 6   Model: 85   Stepping: 4
    Features: aes apic avx avx2 avx512f avx512cd avx512bw avx512vl avx512secondFMA clfsh cmov cx8 cx16 f16c fma hle htt intel lahf mmx msr nonstop_tsc pcid pclmuldq pdcm pdpe1gb popcnt pse rdrnd rdtscp rtm sse2 sse3 sse4.1 sse4.2 ssse3 tdt x2apic
    Number of AVX-512 FMA units: 2
  Hardware topology: Full, with devices
    Packages, cores, and logical processors:
    [indices refer to OS logical processors]
      Package  0: [   0  32] [   1  33] [   2  34] [   3  35] [   4  36] [   5  37] [   6  38] [   7  39] [   8  40] [   9  41] [  10  42] [  11  43] [  12  44] [  13  45] [  14  46] [  15  47]
      Package  1: [  16  48] [  17  49] [  18  50] [  19  51] [  20  52] [  21  53] [  22  54] [  23  55] [  24  56] [  25  57] [  26  58] [  27  59] [  28  60] [  29  61] [  30  62] [  31  63]
    CPU limit set by OS: -1   Recommended max number of threads: 64
    Numa nodes:
      Node  0 (809724567552 bytes mem):   0  32   1  33   2  34   3  35   4  36   5  37   6  38   7  39   8  40   9  41  10  42  11  43  12  44  13  45  14  46  15  47
      Node  1 (811701600256 bytes mem):  16  48  17  49  18  50  19  51  20  52  21  53  22  54  23  55  24  56  25  57  26  58  27  59  28  60  29  61  30  62  31  63
      Latency:
               0     1
         0  1.00  2.10
         1  2.10  1.00
    Caches:
      L1: 32768 bytes, linesize 64 bytes, assoc. 8, shared 2 ways
      L2: 1048576 bytes, linesize 64 bytes, assoc. 16, shared 2 ways
      L3: 23068672 bytes, linesize 64 bytes, assoc. 11, shared 32 ways
    PCI devices:
      0000:00:11.5  Id: 8086:a1d2  Class: 0x0106  Numa: 0
      0000:00:17.0  Id: 8086:2826  Class: 0x0104  Numa: 0
      0000:03:00.0  Id: 1a03:2000  Class: 0x0300  Numa: 0
      0000:1c:00.0  Id: 10de:1db4  Class: 0x0302  Numa: 0
      0000:1e:00.0  Id: 10de:1db4  Class: 0x0302  Numa: 0
      0000:40:00.0  Id: 10de:1db4  Class: 0x0302  Numa: 0
      0000:41:00.0  Id: 10de:1db4  Class: 0x0302  Numa: 0
      0000:5e:00.0  Id: 15b3:1013  Class: 0x0200  Numa: 0
      0000:5e:00.1  Id: 15b3:1014  Class: 0x0200  Numa: 0
      0000:5e:00.2  Id: 15b3:1014  Class: 0x0200  Numa: 0
      0000:5e:00.3  Id: 15b3:1014  Class: 0x0200  Numa: 0
      0000:5e:00.4  Id: 15b3:1014  Class: 0x0200  Numa: 0
      0000:61:00.0  Id: 8086:37d2  Class: 0x0200  Numa: 0
      0000:61:00.1  Id: 8086:37d2  Class: 0x0200  Numa: 0
      0000:86:00.0  Id: 15b3:1013  Class: 0x0200  Numa: 1
      0000:86:00.1  Id: 15b3:1013  Class: 0x0207  Numa: 1
      0000:86:00.2  Id: 15b3:1014  Class: 0x0200  Numa: 1
      0000:86:00.3  Id: 15b3:1014  Class: 0x0200  Numa: 1
      0000:86:00.4  Id: 15b3:1014  Class: 0x0200  Numa: 1
      0000:86:00.5  Id: 15b3:1014  Class: 0x0200  Numa: 1
      0000:d8:00.0  Id: 8086:0a54  Class: 0x0108  Numa: 1
  GPU info:
    Number of GPUs detected: 4
    #0: NVIDIA Tesla V100-PCIE-16GB, compute cap.: 7.0, ECC: yes, stat: compatible
    #1: NVIDIA Tesla V100-PCIE-16GB, compute cap.: 7.0, ECC: yes, stat: compatible
    #2: NVIDIA Tesla V100-PCIE-16GB, compute cap.: 7.0, ECC: yes, stat: compatible
    #3: NVIDIA Tesla V100-PCIE-16GB, compute cap.: 7.0, ECC: yes, stat: compatible


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
M. J. Abraham, T. Murtola, R. Schulz, S. Páll, J. C. Smith, B. Hess, E.
Lindahl
GROMACS: High performance molecular simulations through multi-level
parallelism from laptops to supercomputers
SoftwareX (2015)
DOI: 10.1016/j.softx.2015.06.001
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Páll, M. J. Abraham, C. Kutzner, B. Hess, E. Lindahl
Tackling Exascale Software Challenges in Molecular Dynamics Simulations with
GROMACS
In S. Markidis & E. Laure (Eds.), Solving Software Challenges for Exascale (2015)
DOI: 10.1007/978-3-319-15976-8_1
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Pronk, S. Páll, R. Schulz, P. Larsson, P. Bjelkmar, R. Apostolov, M. R.
Shirts, J. C. Smith, P. M. Kasson, D. van der Spoel, B. Hess, E. Lindahl
GROMACS 4.5: a high-throughput and highly parallel open source molecular
simulation toolkit
Bioinformatics (2013)
DOI: 10.1093/bioinformatics/btt055
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess, C. Kutzner, D. van der Spoel, E. Lindahl
GROMACS 4: Algorithms for highly efficient, load-balanced, and scalable
molecular simulation
J. Chem. Theory Comput. (2008)
DOI: 10.1021/ct700301q
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
D. van der Spoel, E. Lindahl, B. Hess, G. Groenhof, A. E. Mark, H. J. C.
Berendsen
GROMACS: Fast, Flexible and Free
J. Comp. Chem. (2005)
DOI: 10.1002/jcc.20291
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
E. Lindahl, B. Hess, D. van der Spoel
GROMACS 3.0: A package for molecular simulation and trajectory analysis
J. Mol. Mod. (2001)
DOI: 10.1007/s008940100045
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
H. J. C. Berendsen, D. van der Spoel and R. van Drunen
GROMACS: A message-passing parallel molecular dynamics implementation
Comp. Phys. Comm. (1995)
DOI: 10.1016/0010-4655(95)00042-E
-------- -------- --- Thank You --- -------- --------


The number of OpenMP threads was set by environment variable OMP_NUM_THREADS to 64 (and the command-line setting agreed with that)

Input Parameters:
   integrator                     = md
   tinit                          = 0
   dt                             = 0.002
   nsteps                         = 500000
   init-step                      = 0
   simulation-part                = 1
   mts                            = false
   mass-repartition-factor        = 1
   comm-mode                      = Linear
   nstcomm                        = 100
   bd-fric                        = 0
   ld-seed                        = -1167393677
   emtol                          = 10
   emstep                         = 0.01
   niter                          = 20
   fcstep                         = 0
   nstcgsteep                     = 1000
   nbfgscorr                      = 10
   rtpi                           = 0.05
   nstxout                        = 0
   nstvout                        = 0
   nstfout                        = 0
   nstlog                         = 50000
   nstcalcenergy                  = 100
   nstenergy                      = 2500
   nstxout-compressed             = 0
   compressed-x-precision         = 1000
   cutoff-scheme                  = Verlet
   nstlist                        = 10
   pbc                            = xyz
   periodic-molecules             = false
   verlet-buffer-tolerance        = 0.005
   verlet-buffer-pressure-tolerance = -1
   rlist                          = 1.263
   coulombtype                    = Reaction-Field
   coulomb-modifier               = Potential-shift
   rcoulomb-switch                = 0
   rcoulomb                       = 1.2
   epsilon-r                      = 1
   epsilon-rf                     = inf
   vdw-type                       = Cut-off
   vdw-modifier                   = Potential-shift
   rvdw-switch                    = 0
   rvdw                           = 1.2
   DispCorr                       = No
   table-extension                = 1
   fourierspacing                 = 0.147
   fourier-nx                     = 0
   fourier-ny                     = 0
   fourier-nz                     = 0
   pme-order                      = 5
   ewald-rtol                     = 1e-05
   ewald-rtol-lj                  = 0.001
   lj-pme-comb-rule               = Geometric
   ewald-geometry                 = 3d
   epsilon-surface                = 0
   ensemble-temperature-setting   = constant
   ensemble-temperature           = 300
   tcoupl                         = V-rescale
   nsttcouple                     = 10
   nh-chain-length                = 0
   print-nose-hoover-chain-variables = false
   pcoupl                         = Parrinello-Rahman
   pcoupltype                     = Isotropic
   nstpcouple                     = 10
   tau-p                          = 4
   compressibility (3x3):
      compressibility[    0]={ 4.50000e-05,  0.00000e+00,  0.00000e+00}
      compressibility[    1]={ 0.00000e+00,  4.50000e-05,  0.00000e+00}
      compressibility[    2]={ 0.00000e+00,  0.00000e+00,  4.50000e-05}
   ref-p (3x3):
      ref-p[    0]={ 1.00000e+00,  0.00000e+00,  0.00000e+00}
      ref-p[    1]={ 0.00000e+00,  1.00000e+00,  0.00000e+00}
      ref-p[    2]={ 0.00000e+00,  0.00000e+00,  1.00000e+00}
   refcoord-scaling               = No
   posres-com (0x3):
   posres-comB (0x3):
   QMMM                           = false
qm-opts:
   ngQM                           = 0
   constraint-algorithm           = Lincs
   continuation                   = true
   Shake-SOR                      = false
   shake-tol                      = 0.0001
   lincs-order                    = 4
   lincs-iter                     = 1
   lincs-warnangle                = 30
   nwall                          = 0
   wall-type                      = 9-3
   wall-r-linpot                  = -1
   wall-atomtype[0]               = -1
   wall-atomtype[1]               = -1
   wall-density[0]                = 0
   wall-density[1]                = 0
   wall-ewald-zfac                = 3
   pull                           = false
   awh                            = false
   rotation                       = false
   interactiveMD                  = false
   disre                          = No
   disre-weighting                = Conservative
   disre-mixed                    = false
   dr-fc                          = 1000
   dr-tau                         = 0
   nstdisreout                    = 100
   orire-fc                       = 0
   orire-tau                      = 0
   nstorireout                    = 100
   free-energy                    = no
   cos-acceleration               = 0
   deform (3x3):
      deform[    0]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      deform[    1]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
      deform[    2]={ 0.00000e+00,  0.00000e+00,  0.00000e+00}
   simulated-tempering            = false
   swapcoords                     = no
   userint1                       = 0
   userint2                       = 0
   userint3                       = 0
   userint4                       = 0
   userreal1                      = 0
   userreal2                      = 0
   userreal3                      = 0
   userreal4                      = 0
   applied-forces:
     electric-field:
       x:
         E0                       = 0
         omega                    = 0
         t0                       = 0
         sigma                    = 0
       y:
         E0                       = 0
         omega                    = 0
         t0                       = 0
         sigma                    = 0
       z:
         E0                       = 0
         omega                    = 0
         t0                       = 0
         sigma                    = 0
     density-guided-simulation:
       active                     = false
       group                      = protein
       similarity-measure         = inner-product
       atom-spreading-weight      = unity
       force-constant             = 1e+09
       gaussian-transform-spreading-width = 0.2
       gaussian-transform-spreading-range-in-multiples-of-width = 4
       reference-density-filename = reference.mrc
       nst                        = 1
       normalize-densities        = true
       adaptive-force-scaling     = false
       adaptive-force-scaling-time-constant = 4
grpopts:
   nrdf:  6.74142e+06
   ref-t:         300
   tau-t:         0.1
annealing:          No
annealing-npoints:           0
   acc:	           0           0           0
   nfreeze:           N           N           N
   energygrp-flags[  0]: 0

The -nsteps functionality is deprecated, and may be removed in a future version. Consider using gmx convert-tpr -nsteps or changing the appropriate .mdp file field.

Overriding nsteps with value passed on the command line: 1000 steps, 2 ps

Changing rlist from 1.263 to 1.262 for non-bonded 8x8 atom kernels

Changing nstlist from 10 to 25, rlist from 1.262 to 1.407


Update groups can not be used for this system because there are three or more consecutively coupled constraints

GPU-aware MPI was not detected, will not use direct GPU communication. Check the GROMACS install guide for recommendations for GPU-aware support. If you are certain about GPU-aware support in your MPI library, you can force its use by setting the GMX_FORCE_GPU_AWARE_MPI environment variable.

Local state does not use filler particles

1 GPU selected for this run.
Mapping of GPU IDs to the 1 GPU task in the 1 rank on this node:
  PP:0
PP tasks will do (non-perturbed) short-ranged interactions on the GPU
PP task will update and constrain coordinates on the GPU
Using 1 MPI process
Using 64 OpenMP threads 

System total charge: -0.000
Reaction-Field:
epsRF = 0, rc = 1.2, krf = 0.289352, crf = 1.25, epsfac = 138.935
The electrostatics potential has its minimum at r = 1.2
Potential shift: LJ r^-12: -1.122e-01 r^-6: -3.349e-01
Generated table with 1203 data points for 1-4 COUL.
Tabscale = 500 points/nm
Generated table with 1203 data points for 1-4 LJ6.
Tabscale = 500 points/nm
Generated table with 1203 data points for 1-4 LJ12.
Tabscale = 500 points/nm


Using GPU 8x4 nonbonded short-range kernels

NBNxM GPU setup: super-cluster 2x2x2

Using a dual 8x4 pair-list setup updated with dynamic, rolling pruning:
  outer list: updated every 25 steps, buffer 0.207 nm, rlist 1.407 nm
  inner list: updated every  4 steps, buffer 0.020 nm, rlist 1.220 nm
At tolerance 0.005 kJ/mol/ps per atom, equivalent classical 1x1 list would be:
  outer list: updated every 25 steps, buffer 0.269 nm, rlist 1.469 nm
  inner list: updated every  4 steps, buffer 0.033 nm, rlist 1.233 nm

The average pressure is off by at most 0.00 bar due to missing LJ interactions

Using Lorentz-Berthelot Lennard-Jones combination rule

Pinning threads with an auto-selected logical cpu stride of 1

Initializing LINear Constraint Solver

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
B. Hess, H. Bekker, H. J. C. Berendsen, J. G. E. M. Fraaije
LINCS: A Linear Constraint Solver for molecular simulations
J. Comp. Chem. (1997)
DOI: 10.1002/(sici)1096-987x(199709)18:12<1463::aid-jcc4>3.0.co;2-h
-------- -------- --- Thank You --- -------- --------

The number of constraints is 95216

++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
S. Miyamoto, P. A. Kollman
SETTLE: An Analytical Version of the SHAKE and RATTLE Algorithms for Rigid
Water Models
J. Comp. Chem. (1992)
DOI: 10.1002/jcc.540130805
-------- -------- --- Thank You --- -------- --------


++++ PLEASE READ AND CITE THE FOLLOWING REFERENCE ++++
G. Bussi, D. Donadio, M. Parrinello
Canonical sampling through velocity rescaling
J. Chem. Phys. (2007)
DOI: 10.1063/1.2408420
-------- -------- --- Thank You --- -------- --------

There are: 3316463 Atoms

Updating coordinates and applying constraints on the GPU.
Center of mass motion removal mode is Linear
We have the following groups for center of mass motion removal:
  0:  System

Started mdrun on rank 0 Fri Aug  1 01:05:06 2025

           Step           Time
              0        0.00000

   Energies (kJ/mol)
           Bond            U-B    Proper Dih.          LJ-14     Coulomb-14
    1.61528e+05    1.39988e+06   -4.06957e+04    3.43319e+05    4.59320e+06
        LJ (SR)   Coulomb (SR)      Potential    Kinetic En.   Total Energy
    7.73085e+06   -5.21143e+07   -3.79262e+07    8.76607e+06   -2.91601e+07
  Conserved En.    Temperature Pressure (bar)   Constr. rmsd
   -2.91581e+07    3.12788e+02    4.43243e+03    0.00000e+00

           Step           Time
           1000        2.00000

Writing checkpoint, step 1000 at Fri Aug  1 01:05:34 2025


   Energies (kJ/mol)
           Bond            U-B    Proper Dih.          LJ-14     Coulomb-14
    2.85476e+05    6.55756e+05    3.09186e+04    3.53696e+05    4.60791e+06
        LJ (SR)   Coulomb (SR)      Potential    Kinetic En.   Total Energy
    6.39204e+06   -5.15375e+07   -3.92117e+07    8.42189e+06   -3.07898e+07
  Conserved En.    Temperature Pressure (bar)   Constr. rmsd
   -2.93810e+07    3.00507e+02    2.06713e+02    0.00000e+00


Energy conservation over simulation part #1 of length 2 ps, time 0 to 2 ps
  Conserved energy drift: -3.36e-02 kJ/mol/ps per atom


	<======  ###############  ==>
	<====  A V E R A G E S  ====>
	<==  ###############  ======>

	Statistics over 1001 steps using 11 frames

   Energies (kJ/mol)
           Bond            U-B    Proper Dih.          LJ-14     Coulomb-14
    2.79918e+05    7.49781e+05    4.09472e+04    3.54397e+05    4.59652e+06
        LJ (SR)   Coulomb (SR)      Potential    Kinetic En.   Total Energy
    6.47583e+06   -5.14624e+07   -3.89651e+07    8.48604e+06   -3.04790e+07
  Conserved En.    Temperature Pressure (bar)   Constr. rmsd
   -2.93696e+07    3.02796e+02    4.32489e+02    0.00000e+00

          Box-X          Box-Y          Box-Z
    9.36318e+01    2.04277e+01    1.76909e+01

   Total Virial (kJ/mol)
    2.02277e+06   -1.09463e+05    4.10476e+04
   -1.09457e+05    2.53813e+06   -4.45263e+04
    4.10567e+04   -4.45255e+04    2.60311e+06

   Pressure (bar)
    8.05254e+02    1.06197e+02   -2.75273e+01
    1.06191e+02    2.59173e+02    4.14398e+01
   -2.75362e+01    4.14390e+01    2.33040e+02


	M E G A - F L O P S   A C C O U N T I N G

 NB=Group-cutoff nonbonded kernels    NxN=N-by-N cluster Verlet kernels
 RF=Reaction-Field  VdW=Van der Waals  QSTab=quadratic-spline table
 W3=SPC/TIP3p  W4=TIP4p (single or pairs)
 V&F=Potential and force  V=Potential only  F=Force only

 Computing:                               M-Number         M-Flops  % Flops
-----------------------------------------------------------------------------
 Pair Search distance check           16721.633760      150494.704     1.1
 NxN RF Elec. + LJ [F]               356635.708992    13552156.942    94.8
 NxN RF Elec. + LJ [V&F]               3976.074432      214708.019     1.5
 1,4 nonbonded interactions             560.087528       50407.878     0.4
 Shift-X                                135.974983         815.850     0.0
 Bonds                                  117.765648        6948.173     0.0
 Propers                                993.964972      227617.979     1.6
 Virial                                 334.967308        6029.412     0.0
 Stop-CM                                 36.481093         364.811     0.0
 Calc-Ekin                              669.925526       18087.989     0.1
 Urey-Bradley                           383.178796       70121.720     0.5
-----------------------------------------------------------------------------
 Total                                                14297753.475   100.0
-----------------------------------------------------------------------------


      R E A L   C Y C L E   A N D   T I M E   A C C O U N T I N G

On 1 MPI rank, each using 64 OpenMP threads

 Activity:              Num   Num      Call    Wall time         Giga-Cycles
                        Ranks Threads  Count      (s)         total sum    %
--------------------------------------------------------------------------------
 Neighbor search           1   64         41       6.041        811.934  16.2
 Launch PP GPU ops.        1   64       1961       2.082        279.821   5.6
 Force                     1   64       1001       2.195        295.066   5.9
 Wait GPU NB local         1   64       1001       1.757        236.195   4.7
 Wait GPU state copy       1   64       2223      15.469       2079.073  41.4
 NB X/F buffer ops.        1   64        101       0.204         27.435   0.5
 Write traj.               1   64          1       9.157       1230.705  24.5
 GPU constr. setup         1   64          1       0.027          3.690   0.1
 Kinetic energy            1   64        201       0.193         25.911   0.5
 Rest                                              0.205         27.523   0.5
--------------------------------------------------------------------------------
 Total                                            37.332       5017.354 100.0
--------------------------------------------------------------------------------

NOTE: 16 % of the run time was spent in pair search,
      you might want to increase nstlist (this has no effect on accuracy)

               Core t (s)   Wall t (s)        (%)
       Time:     2388.225       37.332     6397.3
                 (ns/day)    (hour/ns)
Performance:        4.633        5.180
Finished mdrun on rank 0 Fri Aug  1 01:05:44 2025

