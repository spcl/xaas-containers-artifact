source_container: spcleth/xaas-artifact:llama.cpp-source-x86_64
working_directory: llamacpp-builds
project_name: llama.cpp
language: cxx
system:
  name: aurora
  system_discovery: ../../../system_discovery/aurora.json
  base_image:
    name: intel/oneapi-hpckit:2025.0.2-0-devel-ubuntu24.04
    provided_features: [ICPX, ONEAPI, SYCL]
    additional_commands: []
mode:
  predefined_config:
    vectorization_flags: avx_512
    gpu_backends: SYCL
    parallel_libraries: [OpenMP]
    fft_libraries: []
    linear_algebra_libraries: MKL
    compiler: icpx
  mode: predefined
